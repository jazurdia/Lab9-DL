{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se anadira droutout a la arquitectura LeNet-5 para mejorar la generalizacion del modelo. \n",
    "# Definir la arquitectura LeNet-5 con Dropout\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.dropout = nn.Dropout(0.5)  # Añadir Dropout con un 50% de probabilidad\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))  # Aplicar Dropout después de la primera capa FC\n",
    "        x = self.dropout(torch.relu(self.fc2(x)))  # Aplicar Dropout después de la segunda capa FC\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el modelo, la función de pérdida y el optimizador\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LeNet5().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "## comprobar si se puede usar cuda con gpu. \n",
    "print(device)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.359000263984253\n",
      "Epoch 2, Loss: 0.13579924102630467\n",
      "Epoch 3, Loss: 0.10573464371139804\n",
      "Epoch 4, Loss: 0.08930337681182039\n",
      "Epoch 5, Loss: 0.07761206855581453\n",
      "Epoch 6, Loss: 0.07075405709274735\n",
      "Epoch 7, Loss: 0.06550046803742492\n",
      "Epoch 8, Loss: 0.06018247390315325\n",
      "Epoch 9, Loss: 0.05528907021235403\n",
      "Epoch 10, Loss: 0.05188241279313224\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()  # Asegurarse de que el modelo esté en modo de entrenamiento (Dropout activo)\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular la métrica de precisión\n",
    "def calculate_accuracy(model, dataloader, device):\n",
    "    model.eval()  # Poner el modelo en modo evaluación (Dropout desactivado)\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.94%\n"
     ]
    }
   ],
   "source": [
    "# Calcular la precisión en el conjunto de prueba\n",
    "accuracy = calculate_accuracy(model, testloader, device)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la arquitectura AlexNet\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 10),  # CIFAR10 tiene 10 clases\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation y normalización para CIFAR-10\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),   # Flip horizontal aleatorio\n",
    "    transforms.RandomCrop(32, padding=4), # Recorte aleatorio con padding\n",
    "    transforms.Resize(224),              # Redimensionar a 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalización\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset CIFAR10\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data2', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root='./data2', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el modelo, la función de pérdida y el optimizador\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = AlexNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar SGD con momentum\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3372866891686568\n",
      "Epoch 2, Loss: 1.1041173325932545\n",
      "Epoch 3, Loss: 0.9518367097048503\n",
      "Epoch 4, Loss: 0.8488741616535065\n",
      "Epoch 5, Loss: 0.7605342088300554\n",
      "Epoch 6, Loss: 0.6945815810462093\n",
      "Epoch 7, Loss: 0.6493865771747916\n",
      "Epoch 8, Loss: 0.6009499154356129\n",
      "Epoch 9, Loss: 0.5765223242056644\n",
      "Epoch 10, Loss: 0.5356589795073585\n",
      "Epoch 11, Loss: 0.5108854698441218\n",
      "Epoch 12, Loss: 0.4870008224302241\n",
      "Epoch 13, Loss: 0.47014428328370195\n",
      "Epoch 14, Loss: 0.44887373133388625\n",
      "Epoch 15, Loss: 0.431289500916553\n",
      "Epoch 16, Loss: 0.41637180050087097\n",
      "Epoch 17, Loss: 0.40375681627360754\n",
      "Epoch 18, Loss: 0.38806021351681647\n",
      "Epoch 19, Loss: 0.3780418832398132\n",
      "Epoch 20, Loss: 0.36395310950667964\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "epochs = 20  # Aumentar el número de épocas para mejorar el rendimiento\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular la métrica de precisión\n",
    "def calculate_accuracy(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.02%\n"
     ]
    }
   ],
   "source": [
    "# Calcular la precisión en el conjunto de prueba\n",
    "accuracy = calculate_accuracy(model, testloader, device)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. ¿Cuál es la diferencia principal entre ambas arquitecturas?\n",
    "\n",
    "La diferencia principal entre LeNet-5 y AlexNet radica en la complejidad y el propósito:\n",
    "- LeNet-5 fue diseñado para tareas sencillas como la clasificación de dígitos en imágenes pequeñas (28x28 píxeles) en el dataset MNIST. Tiene menos capas convolucionales y un número significativamente menor de parámetros.\n",
    "- AlexNet es una red mucho más grande, diseñada para resolver tareas complejas de clasificación en imágenes a gran escala (como el dataset ImageNet con imágenes de 224x224 píxeles). Incluye más capas convolucionales, más filtros y utiliza técnicas como Dropout y normalización local para mejorar el rendimiento y evitar el sobreajuste.\n",
    "\n",
    "b. ¿Podría usarse LeNet-5 para un problema como el que resolvió usando AlexNet? ¿Y viceversa?\n",
    "\n",
    "- LeNet-5 en problemas como los resueltos con AlexNet: No sería adecuado, ya que LeNet-5 fue diseñado para imágenes pequeñas y problemas sencillos. Su capacidad para manejar imágenes más grandes y complejas como las del dataset CIFAR10 sería muy limitada, y probablemente su rendimiento sería muy bajo.\n",
    "- AlexNet en problemas como los resueltos con LeNet-5: Aunque podría usarse, AlexNet sería innecesariamente grande y complejo para resolver problemas sencillos como la clasificación de dígitos en el dataset MNIST. Esto sería ineficiente y llevaría a un sobreajuste en este tipo de problemas simples.\n",
    "\n",
    "c. Indique claramente qué le pareció más interesante de cada arquitectura\n",
    "\n",
    "- LeNet-5: Lo más interesante de LeNet-5 es su simplicidad y eficacia en resolver problemas de clasificación de imágenes pequeñas como MNIST. A pesar de ser una red bastante antigua, sigue siendo efectiva para tareas específicas.\n",
    "- AlexNet: La introducción de técnicas como Dropout y el uso de un gran número de filtros y capas convolucionales la hace mucho más poderosa para tareas complejas. Su capacidad para procesar imágenes a gran escala y su influencia en arquitecturas modernas es lo más destacable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "1. Investigue e indique en qué casos son útiles las siguientes arquitecturas, agregue imagenes si esto le ayuda a una mejor comprensión\n",
    "\n",
    "    1. GoogleNet (Inception)\n",
    "   \n",
    "    GoogleNet es útil en tareas de clasificación de imágenes a gran escala donde se busca un equilibrio entre precisión y eficiencia computacional. La arquitectura Inception permite procesar múltiples escalas de características en paralelo, reduciendo el número de parámetros y evitando el sobreajuste. Es ideal para dispositivos con recursos limitados y para mejorar el rendimiento en conjuntos de datos como ImageNet.\n",
    "\n",
    "    2. DenseNet (Densely Connected Convolutional Networks)\n",
    "\n",
    "    DenseNet es beneficioso cuando se requiere una mejor propagación de características y gradientes a través de la red. Al conectar cada capa con todas las capas posteriores, mejora el flujo de información y reduce el problema del gradiente desaparecido. Es útil en tareas donde se necesita una alta precisión con un número relativamente bajo de parámetros.\n",
    "\n",
    "    3. MobileNet\n",
    "\n",
    "    MobileNet es ideal para aplicaciones móviles y embebidas donde los recursos computacionales y energéticos son limitados. Utiliza convoluciones separables en profundidad para reducir significativamente el tamaño del modelo y los requisitos de cómputo, manteniendo una precisión aceptable en tareas como clasificación y detección de objetos en dispositivos con poca potencia.\n",
    "\n",
    "    4. EfficientNet\n",
    "\n",
    "    EfficientNet es útil cuando se busca maximizar la precisión mientras se minimiza el costo computacional. Introduce un método de escalamiento compuesto que equilibra la profundidad, el ancho y la resolución de la red. Es adecuado para aplicaciones que requieren alta precisión con eficiencia computacional, como servicios en la nube y aplicaciones en tiempo real.\n",
    "\n",
    "2. ¿Cómo la arquitectura de transformers puede ser usada para image recognition?\n",
    "\n",
    "Los transformers pueden aplicarse al reconocimiento de imágenes dividiendo una imagen en parches y tratándolos como una secuencia de tokens, similar al procesamiento en NLP. Modelos como Vision Transformer (ViT) utilizan esta técnica para capturar relaciones globales entre diferentes partes de la imagen, permitiendo un rendimiento superior en tareas de clasificación sin depender de convoluciones tradicionales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrantes\n",
    "\n",
    "- Angel Castellanos\n",
    "- Diego Morales\n",
    "- Alejandro Azurdia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaPytorchLatest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
